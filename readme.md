# lab

## Ollama

Install Ollama and serve a model:

```bash
curl -s https://raw.githubusercontent.com/mateothegreat/lab/main/bin/ollama-e2e | bash
```

Run a model with verbose output:

```bash
curl -s https://raw.githubusercontent.com/mateothegreat/lab/main/bin/ollama-e2e | bash "$1" "What is the capital of France?"
```
